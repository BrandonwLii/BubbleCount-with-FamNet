{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90101142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import BubbleCount.image_preprocess as image_preprocess\n",
    "import BubbleCount.csv_helpers as csv_helpers\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "# Helper function\n",
    "def simplify_target_name(target):\n",
    "    temp = target.split('_')[1:-1]\n",
    "    temp = '_'.join(temp)\n",
    "    serial_number = temp.split('.')[-1]\n",
    "    batch_name = '.'.join(temp.split('.')[0:-2])\n",
    "\n",
    "    return f\"{batch_name}_{serial_number}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca36317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Using CPU mode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from BubbleCount.counting_model import CountingPipe\n",
    "model = CountingPipe()  # Only really need the count_hybrid() function in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1768933",
   "metadata": {},
   "source": [
    "### Arguments:\n",
    "`raw_img_dir` - Folder containing uncropped images to be cropped to AOI <br>\n",
    "`target_path` - Folder for images cropped to AOI <br>\n",
    "`result_path` - .csv file containing count predictions <br>\n",
    "`output_dir` - Folder for output images (Density plot, Graph, Overlaid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109aca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"raw_img_dir\": \"./2025/Images/SEN10_1.8_6_300-400\", # images to be cropped\n",
    "    \"target_path\": \"./2025/Targets\", # cropped images\n",
    "    \"result_path\": \"./2025/Outputs/out.csv\", # csv containing counts\n",
    "    \"output_dir\": \"./2025/Outputs/\", # output images\n",
    "    \n",
    "\n",
    "\n",
    "    # Do not modify\n",
    "    \"sample_path\": \"./Exemplars/\",\n",
    "    \"model_path\": \"./data/pretrainedModels/FamNet_Save1.pth\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072448a",
   "metadata": {},
   "source": [
    "### Image cropping\n",
    "`region` - y1, x1, y2, x2 coordiantes for a bounding box to crop raw images <br><br>\n",
    "\n",
    "Takes images from `raw_img_dir` and outputs cropped iamges in `target_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop images to AOI\n",
    "region=[65, 770, 1090, 970]\n",
    "image_preprocess.crop_to_interest(image_dir=args[\"raw_img_dir\"],region=region,output_dir=args[\"target_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3f896",
   "metadata": {},
   "source": [
    "### Predict and output\n",
    "\n",
    "Takes all images from `target_path`, overlays exemplar bubbles from `sample_path`, then predicts and generates density plots, graphs, and the overlaid image to `output_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e8990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/600 [00:00<?, ?it/s]c:\\Users\\Brandon\\Desktop\\fellowship2025\\BubbleCount-with-FamNet\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Brandon\\Desktop\\fellowship2025\\BubbleCount-with-FamNet\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing images:   1%|          | 6/600 [00:07<13:04,  1.32s/it]c:\\Users\\Brandon\\Desktop\\fellowship2025\\BubbleCount-with-FamNet\\utils.py:398: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=figsize)\n",
      "Processing images: 100%|██████████| 600/600 [14:20<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The counts are saved to ./2025/Outputs/out.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_to_csv = []\n",
    "\n",
    "# Load exemplars and targets\n",
    "Exemplars = image_preprocess.load_exemplars_from_directory(args[\"sample_path\"], reverse_bbox=False)\n",
    "Targets = image_preprocess.load_target_images_from_directory(args[\"target_path\"])\n",
    "\n",
    "sample_image = Exemplars[1]\n",
    "\n",
    "csv_helpers.backup_and_clear_csv(args[\"result_path\"])\n",
    "\n",
    "with open(args[\"result_path\"], 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Exemplar\", \"num_exemps\", \"rev_bbox\", \"Target\", \"Count\"])\n",
    "\n",
    "    total = len(Targets)\n",
    "    count = 0\n",
    "    \n",
    "    for target_image in tqdm(Targets, desc=\"Processing images\"):\n",
    "        num_exemps = 4\n",
    "        # Creating the hybrid\n",
    "        hybrid, hybrid_boxes = image_preprocess.insert_cropped(sample_image['image'], target_image['image'], sample_image['box'], num_exemps)\n",
    "        target_name = f\"{simplify_target_name(target_image['file_name'])}_{num_exemps}exemps\"\n",
    "\n",
    "        # Count and output into separate files\n",
    "        hybrid_count = model.count_hybrid_and_visualize_separate(hybrid, hybrid_boxes, sample_image[\"file_name\"], target_name,output_directory=args[\"output_dir\"])\n",
    "\n",
    "        result_to_csv.append([sample_image['file_name'], num_exemps, False, target_name, hybrid_count])\n",
    "\n",
    "        # append to csv\n",
    "        writer.writerows(result_to_csv)\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "print(f\"The counts are saved to {args['result_path']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae274ba1",
   "metadata": {},
   "source": [
    "### Video creation tool\n",
    "`dir` - Category of images to create video from. Options: `Density`, `Graphs`, `Overlaid`. <br>\n",
    "`fps` - Frames per second of final video. Default: 10<br>\n",
    "\n",
    "Takes images from `output_dir` and the specified `dir` and creates a video with the specified `fps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Generate videos from images\n",
    "dir = \"Overlaid\" # \"Density\" or \"Graphs\" or \"Overlaid\"\n",
    "fps = 10\n",
    "\n",
    "input_folder = f'{args[\"output_dir\"]}{dir}/'\n",
    "\n",
    "print(input_folder)\n",
    "\n",
    "# Get the list of image files in the input folder\n",
    "image_files = sorted([f for f in os.listdir(input_folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "\n",
    "# Read the first image to get its dimensions\n",
    "first_image = cv2.imread(os.path.join(input_folder, image_files[0]))\n",
    "height, width, _ = first_image.shape\n",
    "\n",
    "# Create a VideoWriter object to save the video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Specify the codec for the output video file\n",
    "video = cv2.VideoWriter(f\"{input_folder}video.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "# Iterate over each image and write it to the video\n",
    "for image_file in image_files:\n",
    "    print(image_file)\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    frame = cv2.imread(image_path)\n",
    "    video.write(frame)\n",
    "\n",
    "# Release the video writer and close the video file\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bubblecount-with-famnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
